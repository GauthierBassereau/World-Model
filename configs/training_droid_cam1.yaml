logging:
  project: world_model
  entity: null
  run_name: dv4_jit
  output_dir: checkpoints
  log_interval: 1
  signal_level_log_limit: 100
  checkpoint_interval: 500

trainer:
  loss_type: position
  loss_weighting: linear
  loss_weighting_intercept: 0.1
  loss_weighting_slope: 0.9
  loss_rms_normalization: True
  loss_rms_decay: 0.99
  evaluation_interval: 500
  grad_accum_steps: 4
  precision: bf16
  seed: 3
  resume: false
  load_checkpoint: null

evaluator:
  video_sample_indices: [0, 1, 3, 4]
  rollout_start_frame: 6
  rollout_signal_level: 0.95
  precision: bf16
  max_batches: 10
  denoising_metrics_indices: [0, 1, 2, 3, 4, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 96, 97, 98, 99]
  save_denoising_frames: false

optimizer:
  lr:
    "0": 1.0e-6
    "1000": 3.0e-4
  eps: 1.0e-08
  grad_clip_norm: 10.0
  weight_decay: 0.0

ema:
  enabled: false
  decay: 0.9995
  start_step: 5000

train_dataloader:
  batch_size: 256
  shuffle: true
  num_workers: 4
  pin_memory: true

train_dataset:
  sequence_length_distribution:
    "20": 1.0
  fps: 5.0
  action_dim: 7
  weights:
    droid: 1.0
  reference_dataset: droid
  datasets:
    droid:
      type: lerobot
      repo_id: aractingi/droid_1.0.1
      episodes: null
      excluded_episodes: [0, 1, 2, 3, 4, 5, 6, 7]
      episode_midpoint_only: false
      cameras:
        observation.images.exterior_1_left: 1.0
        # observation.images.exterior_2_left: 0.0
        # observation.images.wrist_left: 0.0
      action_mode: relative_endeffector
      action_normalization: null
      independent_frames_probability: 0.0
      use_action_probability: 1.0

eval_dataloader:
  batch_size: 8
  shuffle: false
  num_workers: 0
  pin_memory: false

eval_dataset:
  sequence_length_distribution:
    "40": 1.0
  fps: 5.0
  action_dim: 7
  weights:
    droid: 1.0
  reference_dataset: droid
  datasets:
    droid:
      type: lerobot
      repo_id: aractingi/droid_1.0.1
      episodes: [0, 1, 2, 3, 4, 5, 6, 7]
      excluded_episodes: null
      episode_midpoint_only: true
      cameras:
        observation.images.exterior_1_left: 1.0
        # observation.images.exterior_2_left: 1.0
        # observation.images.wrist_left: 1.0
      action_mode: relative_endeffector
      action_normalization: null
      independent_frames_probability: 0.0
      use_action_probability: 1.0

signal_scheduler:
  mode: "uniform"  # {"resolution_shift", "linear_shift", "uniform", "logit_normal"}
  min_value: 0.0
  max_value: 1.0

euler_solver:
  number_steps: 50
  min_denom: 0.05
  timestep_schedule: "linear"

world_model: # ~400M parameters
  input_dim: 768
  latent_dim: 768
  bottleneck_dim: 128
  action_dim: 7
  num_registers: 4
  depth: 24
  num_heads: 16
  mlp_multiplier: 4.0
  temporal_attention_interval: 3
  temporal_context_length: 15
  rope_base: 10000.0
  qk_norm_eps: 1.0e-06
  attn_logit_softcapping: 50.0 # None for no softcapping -> able to use fused_attention